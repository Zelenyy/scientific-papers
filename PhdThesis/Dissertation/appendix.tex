\chapter{Метод статистической регуляризации Турчина}\label{app:A}

Оригинальный метод регуляризации изложен в работах \cite{turchin, turovceva}. Работа~\cite{statreg} дает некоторые обобщения и результаты по практическом применению метода.  В этом приложении изложены основные положения методики
\section{Стратегия}
Сформулируем нашу задачу в терминах математической статистики: по известной реализации $f$ нам нужно оценить значение параметра $\varphi$. Функционал $\hat{S}$ определяющий $\varphi$ на основе $f$ мы будем называть \textit{стратегией}. Для того чтобы определять какие стратегии более оптимальные мы введем \textit{квадратичную функцию потерь}:
\begin{equation}
L(\varphi,\hat{S}[f]) = ||\hat{\varphi}-\hat{S}[f])||_{L_2},
\end{equation}
где $\hat{\varphi}$ --- наилучшее решение. Тогда потери для выбраной нами стратегии задаются \textit{функцией риска}:
\begin{equation}
R_{\hat{S}[f]}(\varphi) \equiv E[L(\varphi,\hat{S}[f])] = \int L(\varphi,\hat{S}[f])P(f|\varphi)df,  
\end{equation}
здесь $P(f|\varphi)$ определяет плотность веростности нашего ансамбля по которому производится усреднение потерь. Этот ансамбль образован гипотетическим многократным повторением  измерений $f$ при заданном $\varphi$, таким образом $P(f|\varphi)$ это та самая известная нам плотность вероятности $f$, полученная в эксперименте.

Согласно Байессовскому подходу предлагается рассмотреть $\varphi$, как \textbf{случайную переменную} с \textit{априорной плотностью вероятности} $P(\varphi)$, выражающую \textbf{достоверность} различных возможных законов природы. $P(\varphi)$ определяется на основе информации, существующей до проведения эксперимента. Тогда выбор оптимальной стратегии основывается на минимизации \textit{апостериорного риска}:
\begin{equation}
r_{\hat{S}}(\varphi) \equiv E_{\varphi}E_{f}[L(\varphi,\hat{S}[f])|\varphi]
\end{equation}
В этом случае оптимальная стратегия хорошо известна:
\begin{equation}
\hat{S}[f] = E[\varphi|f] = \int \varphi P(\varphi|f)d\varphi
\label{eq:opt}
\end{equation}

\noindent  где \textit{апостерионая плотность} $P(\varphi|f)$ определяется по теореме Баейса:
\begin{equation}
P(\varphi|f)= \frac{P(\varphi)P(f|\varphi)}{\int d\varphi P(\varphi)P(f|\varphi)} 
\end{equation}
\noindent Кроме того такой подход позволит определить дисперсию (корреляционную функцию) полученного решения:
\begin{equation}
D(x_1,x_2)  = E[\varphi(x_1) - \hat{S}[f](x_1)][\varphi(x_2) - \hat{S}[f](x_2)]
\end{equation}
Итак мы получили оптимальное решение уравнения (\ref{eq:opereq}), введя априорную плотность $P(\varphi)$. Если исследователь уже обладает какой-либо априорной информацией (априорной плотностью $P(\varphi)$), он может просто посчитать интегралы (\ref{eq:opt}) и получить ответ. Для случая, если такой информации нет, в следующем параграфе описывается какой минимальной информацией может обладать исследователь и как её использовать для получения регулязованного решения.


\section{Априорная информация}
\label{sec:theory:aprior}
%\epigraph{Если в мире всё бессмысленно, — сказала Алиса, — что мешает выдумать какой-нибудь смысл?}{Льюис Кэрролл "Приключения Алисы в Стране чудес"}

%В курсе физики, изучаемом студентами университетов, используются различный математический аппарат, и при этом подразумевается само собой разумеющимся возможность корректного использования этого аппарата. Например, если задача требует вычисления производной некоторой физической величины, то предполагается, что функция, описывающую эту величину, дифферинцируема. Говоря языком байесовской статистики, в задаче априорно предпалагается что событие "функция дифферинцируема" --- достоверно (имеет вероятность равную единице). Таким образом, одним из видов априорной информации, доступной исследователю, является гладкость функции. Именно на её основе мы построим наш регуляризующий алгоритм. Кроме того, надо помнить, что введение априорной информации --- это добавление к анализу некоторого субъективного мнения лица, проводящего анализ. Влияние этого мнения следует свести к минимуму, и, вводя априорную плотность вероятности, необходимо, чтобы \textit{информация Шеннона} относительно  $\varphi(x)$, содержащаяся в $P(\vec{\varphi})$, была минимальной.

При работе с Байесовской статистикой ключевым вопросом всегда является выбор априорной вероятности, специфичной для конкретной задачи. Наиболее часто встречающееся в физике ограничение на вид исследуемых функций - это требование непрерывности и гладкости, причем под гладкостью подразумевается не только наличие непрерывной второй производной, но и ее сравнительно маленькое значение. Это связано с тем, что в физических процессах как правило не бывает резких перепадов. Требование минимальной гладкости является очевидным выбором для априорной информации. Поскольку конкретное ограничение на значение второй производной обычно неизвестно, можно также потребовать, чтобы дополнительная информация, возникающая в результате ограничения была минимальной.

Эту задачу можно формализовать следующим образом: требуется найти $P(\varphi)$, при котором функционал информации Шеннона:

\begin{equation}
\label{eq:inforamation}
I[P(\varphi)] = \int \ln{P(\varphi)} P(\varphi) d\varphi
\end{equation}
минимален, и при этом выполнялись следующие условия:
\begin{enumerate}
    \item Плотность вероятности нормированна на единицу:
    \begin{equation}
    \int P(\varphi) d\varphi = 1
    \end{equation}
    
    \item Условие на гладкость $\varphi$. Пусть $\hat{\Omega}$ --- некоторый функционал характеризующий гладкость функции. Тогда потребуем, чтобы достигалось определённое значение следующего выражения:
    \begin{equation}
    \label{eq:glad}
    \int \langle \varphi,\hat{\Omega}\varphi \rangle P(\varphi) d\varphi = \omega,
    \end{equation}
    Обратим внимание на то что значение параметра $\omega$, скорее всего, неизвестно, и способы его определения будут рассмотрены далее в обзоре.
\end{enumerate}
Для поиска условного экстремума используем метод Лагранжа. Функция Лагранжа:
\begin{equation}
L(\varphi, \lambda, \mu) = \ln{P(\varphi)} P(\varphi) + \lambda \langle \varphi,\hat{\Omega}\varphi \rangle P(\varphi) + \mu P(\varphi)
\end{equation}
Подставляем её в уравнение Эйлера-Лагранжа:
\begin{equation}
\frac{\partial L}{\partial \varphi} = P'({\varphi})(1 + \ln{P({\varphi})}  + \lambda \langle \varphi,\hat{\Omega}\varphi \rangle + \mu ) = 0
\end{equation}
Получаем два варианта. Решение уравнения $P'({\varphi}) = 0$ не очень интересно, поскольку возрвращает нас к равновероятным ${\varphi}$ и не регуляризованому решению.
Интересное решение:
\begin{equation}
P({\varphi}) = \exp(-1 + \mu + \lambda \langle \varphi,\hat{\Omega}\varphi \rangle)
\label{eq:eqlagr}
\end{equation}
Обычно следует подставить эту функцию в условия и получить значения параметров $\lambda$ и $\mu$. Но мы пойдем другим путем. Сделаем замену переменных: $\lambda = -\frac{\alpha}{2}$, $ C=\exp(-1 + \mu)$ и подставим в (\ref{eq:eqlagr}):
\begin{equation}
P({\varphi}) = C\exp(-\frac{\alpha}{2} \langle \varphi,\hat{\Omega}\varphi \rangle)
\end{equation}
Тогда мы увидим, что априорная плотность вероятности $P(\varphi)$ это есть плотность \textit{действительного обобщенного случайного гауусового процесса} с функционалом математического ожидания тождественно равным нулю и корреляционным функционалом равным $\alpha \hat{\Omega}[\varphi,\varphi]$, или иначе говоря функция совместного распределения конечномерного представления $\vec{\varphi}$ имеет гауссов вид:
\begin{equation}
P_{\alpha}(\vec{\varphi})  = \frac{\alpha^{Rg(\Omega)/2}\det\Omega^{1/2}}{(2\pi)^{N/2}} \exp(-\frac{1}{2} (\vec{\varphi},\alpha\Omega\vec{\varphi})),
\end{equation}
где $\Omega$ задает конечномерное представление функционала $\hat{\Omega}$, а $\alpha = 1/\omega$.
Таким образом мы получаем наилучшую стратегию, зависящую от параметра $\alpha$:
\begin{equation}
\hat{S}_{\alpha}[f] =  \frac{\int \varphi P(\varphi)_{\alpha}P(f|\varphi) d\varphi }{\int P(\varphi)_{\alpha}P(f|\varphi)d\varphi }
\label{eq:opt_alpha}
\end{equation}
Значение параметра $\alpha$ на этом этапе неизвестно, и может быть получено следующими способами:
\begin{itemize}
    \item напрямую из каких-то внешних данных или подобрано вручную (в этом частном случае результаты работы метода эквиваленты регуляризации Тихонова),
    \item как максимум апостериорной вероятности $P(\alpha|f)$, которую можно определить по теореме Байеса: \begin{equation}
    P(\alpha|\vec{f}) \sim P(\alpha)P(\vec{f}|\alpha),
    \end{equation}
    где
    \begin{equation}
    \label{eq:prob_f_alpha}
    P(\vec{f}|\alpha) = \int d\vec{\varphi} P(\vec{f}|\vec{\varphi})P(\vec{\varphi}|\alpha)
    \end{equation}
    \item как среднее по всем возможным $\alpha$, определив априорную плотность вероятности как:
    \begin{equation}
    P(\varphi) = \int d\alpha P(\alpha) P(\varphi|\alpha),
    \end{equation}
    причем в соответствии с байесовским подходом, можно принять все $\alpha$ равновероятными.
\end{itemize}
Для последнего случая нетрудно показать, что усреденение априорной вероятности о $\varphi$ по априорной информации об $\alpha$ эквивалентно усреденнию наилучшей стратегии зависящей от $\alpha$ по апостериорной вероятности $P(\alpha|f)$:
\begin{equation}
\begin{split}
\int d\alpha \hat{S}_{\alpha}[f] P(\alpha|f) = \int d\alpha \left(\frac{\int \varphi P(f|\varphi) P(\varphi|\alpha)d\varphi}{\int P(f|\varphi) P(\varphi|\alpha)d\varphi} \right) * \frac{P(f|\alpha)P(\alpha)}{\int d\alpha P(f|\alpha)P(\alpha)} = \\
= \int d\alpha\left(\frac{\int \varphi P(f|\varphi) P(\varphi|\alpha)d\varphi}{\int P(f|\varphi) P(\varphi|\alpha)d\varphi} \right) * \frac{\left(\int d\varphi P(f|\varphi)P(\varphi|\alpha)\right)P(\alpha)}{\int d\alpha\int d\varphi P(f|\varphi)P(\varphi|\alpha)P(\alpha)} = \\ =
\frac{\int d\alpha \left( \int \varphi P(f|\varphi) P(\varphi|\alpha)d\varphi \right)*P(\alpha)}{\int d\alpha\int d\varphi P(f|\varphi)P(\varphi|\alpha)P(\alpha)} =  \frac{\int d\varphi \varphi P(f|\varphi) \int d\alpha P(\varphi|\alpha)P(\alpha)}{\int d\varphi P(f|\varphi) \int d\alpha P(\varphi|\alpha)P(\alpha)} = \\=
\frac{\int \varphi P(\varphi)_{\alpha}P(f|\varphi) d\varphi }{\int P(\varphi)_{\alpha}P(f|\varphi)d\varphi} = \hat{S}[f]
\end{split} 
\end{equation}

\section{Алгебраизация}
Интеграл (\ref{eq:opt}) является лебеговым интегралом, что затрудняет его прикладное использование. Кроме того на практике нам известна не функция $f(y)$, набор измерений этой функции в конечном числе точек. Следовательно необходимо перейти из непрерывного пространства функций в параметризованное дискретное представление. Такой переход называется алгебраизацией. Наиболее очевидным и однозначным образом алгебраизуется измеряемая функция $f(y)$, она заменяется вектором $\vec{f}$ --- набором случайных величин с известной плотностью вероятности, представляющих собой результат измерения в конечном числе точек. Замена функции $\varphi(x)$ и операторов $\hat{K}$ и $\hat{\Omega}$, на их дискретные аналоги --- вектор $\vec{\varphi}$ и матрицs $K$ и $\Omega$, может проводиться различными методами. 
При этом нужно учитывать, что в некоторых случаях представление функции при помощи вектора конечной размерности приводит к частичной потере информации.
В результате алгебраизации операторное уравнение (\ref{eq:opereq}) преобразуется в систему линейных уравнений
\begin{equation}
\vec{f} = K\vec{\varphi},
\label{eq:algebr}
\end{equation}

Для алгебраизации функции $\varphi(x)$, мы будем раскладывать её по некоторой системе функций $\{T_n\}$:
\begin{equation}
\varphi(x) = \sum \limits_n \varphi_n T_n(x).
\end{equation}
Таким образом компонентами вектора $\vec{\varphi}$ являются коэффициенты этого разложения. Тогда элементы матрицы $K$, вычисляются как:
\begin{equation}
K_{mn} = (\hat{K}T_n(x))(y_m),
\end{equation}
где $y_m$ --- точки в которых производились измерения. Элементы матрицы $\Omega$ будем вычислять по формуле:
\begin{equation}
\Omega_{ij} = \int\limits_a^b \left(\frac{d^pT_i(x)}{dx}\right)\left(\frac{d^pT_j(x)}{dx}\right)dx,
\end{equation}
где $a$ и $b$ границы интервала на котором определена функция $\varphi(x)$.
Для перерасчета ошибок следует использовать формулу дисперсии линейной комбинации случайных величин:
\begin{equation}
D[\varphi(x)] = D[\sum \limits_n \varphi_n T_n(x)] = \sum\limits_{i,j} \varphi_i\varphi_j cov(T_i(x), T_j(x)).
\end{equation}

В данной работе будет использоваться три способа алгебраизации, основанные на трех разложениях: в тригонометрический ряд Фурье, по полиномам Лежандра и по B-сплайнам ("базисным сплайнам"). 
Рассмотрим первые два случая. Компонентами вектора $\vec{\varphi}$ будут коэффициенты Фурье по выбранным системам функций. Обратим внимание, что в для данных систем функций компоненты вектора $\vec{\varphi}$ не связанны с какими-либо точками промежутка на котором определена функция $\varphi(x)$,  а влияют на результат во всех точках промежутка. Кроме того, обратим внимание, что количество членов ряда, которое нужно взять при алгебраизации не связано с количеством экспериментальных точек. Каждое экспериментальное измерение содержит информацию обо всех компонентах вектора $\vec{\varphi}$. Вопрос определения необходимого числа членов разложения рассмотрен в~\ref{sec:basisnumber}
Перейдем к третьему случаю, имеющему некоторые интересные особенности. B-сплайн это кусочно-полиномиальная функция, положительная на некоторых последовательных участках  некоего интервала и равная нулю на прочих участках интервала. Для определения B-сплайна $k$-порядка на $i$-том участке некоторого интервала используется рекурсивная формула:
\begin{equation}
B_{i1} = 
\begin{cases}
1, &\text{если $x_i \leq t \leq x_{i-1},$}\\
0, &\text{если $t \notin (x_i, x_{i-1})$}
\end{cases}
\label{eq:B-spline}
\end{equation}
$$ B_{ik} (t) = \frac{(t-x_i)B_{i,k-1}(t)}{x_{i+k-1} - x_i} - \frac{(x_{i+k}-t)B_{i+1,k-1}(t)}{x_{i+k} - x_{i+1}} .$$
Любую сплайн функцию $S_k(x)$ можно представить как сумму B-сплайнов:
$$
S_k(x) = \sum \limits_i \alpha_i B_{ik}
$$
Таким образом компонентами вектора $\vec{\varphi}$ будут коэффициенты $\alpha_i$ данного разложения. В отличии от двух предыдущих случаев когда компоненты вектора $\vec{\varphi}$ влияли на весь промежуток, теперь эти компоненты оказывают локальное влияние: каждый компонент влияет только на те промежутки, на которых B-сплайн соответствующий данному компоненту не равен нулю (это получается k+1 последовательных промежутка). К тому же имеются особенности в поведении на краях интервала, благодаря которым можно устанавливать граничные условия: для каждого из краев можно зафиксировать должна ли функция $\varphi(x)$ быть равной нулю на данном краю или нет. Остановимся на последнем пункте более подробно. Рассмотрим некоторое разбиение $\{x_i\}$, например разобьем интервал $[1;5]$ на девять промежутков и построим B-сплайны согласно формуле ~\ref{eq:B-spline} (см. рис. ~\ref{pic:Bspline}). Как мы видим, только первый и последний B-сплайн на соответсвенно левой и правой границе не принимают нулевого значения. Именно эти B-сплайны отвечают за ненулевое значение востанавливаемой функции  $\varphi(x)$ на концах интервала, и если не использовать их при алгебраизации, то на соотвествующей границе будет закрепленно нулевое значение для восстанавливаемой функции $\varphi(x)$.
%\begin{figure}[h!]
%	\label{pic:Bspline}
%	    \center{\includegraphics[scale=0.45]{boundary}}
%	    \caption{B-сплайны.}	
%\end{figure}

\section{Случай гауссовых шумов}

Наиболее распространенным в экспериментальной физике является случай, когда разброс результатов эксперимента подчиняется нормальному распределению. В этом случае регуляризация имеет аналитическое решение.
Пусть вектор измерений $f$ имеет ошибки, описываемые многомерным гауссовым распределением с ковариационной матрицей $\Sigma$:

\begin{equation}
P(\vec{f}|\vec{\varphi}) = \frac{1}{(2\pi)^{M/2}|\Sigma|^{1/2}} \exp(-\frac{1}{2}(\vec{f} - K\vec{\varphi})^T\Sigma^{-1}(\vec{f} - K\vec{\varphi}))
\label{eq:gaussP}
\end{equation}
Сделаем некоторые преобразования. Введем дополнительные обозначения: $$b^T = \vec{f}^T\Sigma^{-1}K,  B = K^T\Sigma^{-1}K.$$
Тогда: $$\vec{f}^T\Sigma^{-1}\vec{f} = \vec{f}\Sigma^{-1}K^{T}K^{-1T}\Sigma^{T}\Sigma^{-1T} KK^{-1}\vec{f} = b^{T}B^{-1}b,$$ и:
\begin{equation}
\label{eq:aposteoriphi}
P(\vec{f}|\vec{\varphi})P(\vec{\varphi}|\alpha) = \frac{\alpha^{Rg(\Omega)/2}\det\Omega^{1/2}}{(2\pi)^{(N+M)/2}|\Sigma|^{1/2}}\exp(-\frac{1}{2}b^{T}B^{-1}b) \exp(-\frac{1}{2} (\vec{\varphi},(B+\alpha\Omega)\vec{\varphi}) + b\vec{\varphi})
\end{equation}
Не трудно заметить, что поскольку вероятности $P(\vec{\varphi})$ и $P(\vec{f}|\vec{\varphi})$ имеют гауссов вид относительно $\vec{\varphi}$, то и их произведение(апостериорная плотность вероятности) получилась гауссовой, а поскольку наилучшее решение является математическим ожидание данного распределения, не составляет труда выписать это решение и его ковариационную матрицу (зависящие от параметра регуляризации):
\begin{equation} \label{eq:analit_solv}
\hat{S}_{\alpha}[\vec{f}] = (K^T\Sigma^{-1}K+\alpha\Omega)^{-1}K^T\Sigma^{-1T}\vec{f}
\end{equation}

\begin{equation} \label{eq:analit_var}
\texttt{cov}_{\alpha}(\varphi_m, \varphi_n) = ||(K^T\Sigma^{-1}K+\alpha^*\Omega)^{-1}||_{mn}
\end{equation}

Как показано в пунтке ~\ref{sec:theory:aprior}, чтобы получить оптимальное решение, не зависящее от параметра регуляризации, необходимо усреднить полученный результат по апострериорной вероятности:

\begin{equation}
\label{eq:solveAposteriorAlpha}
\hat{S}[f] = \int \hat{S}_{\alpha}[\vec{f}] P(\alpha|\vec{f}) d \alpha
\end{equation}

\begin{equation}
\label{eq:varAposteriorAlpha}
\texttt{cov}(\varphi_m, \varphi_n) = \int \texttt{cov}_{\alpha}(\varphi_m, \varphi_n) P(\alpha|\vec{f}) d \alpha
\end{equation}

$P(\alpha|\vec{f})$ определяется интегралом (\ref{eq:prob_f_alpha}). Возьмем этот интеграл, воспользовавшись его сходством с многомерным нормальным распределением:
\begin{equation}
\label{eq:alphaaposter}
P(\alpha|\vec{f}) = C \alpha^{\frac{Rg(\Omega)}{2}}\sqrt{|(B+\alpha\Omega)^{-1}|}\exp(-\frac{1}{2}b^{T}B^{-1}b)\exp(\frac{1}{2}b^{T}(B+\alpha\Omega)^{-1}b),
\end{equation}
где $C$ не зависит от $\alpha$, и определяется из условия нормировки. Полученная формула позволяет взять интегралы (\ref{eq:solveAposteriorAlpha}) и (\ref{eq:varAposteriorAlpha}) численно.
Кроме того, вместо вычисления этих интегралов можно определить наиболее вероятное $\alpha$, как максимум логарифма вероятности:
\begin{equation}
\ln{P(\alpha|\vec{f})} = \ln{C} + \frac{Rg(\Omega)}{2}\ln{\alpha} - \frac{1}{2}\ln{|B+\alpha\Omega|}  + \frac{1}{2}b^{T}(B+\alpha\Omega)^{-1}b,
\end{equation}
и подставить полученное значение в формулы (\ref{eq:analit_solv}) и (\ref{eq:analit_var}).

